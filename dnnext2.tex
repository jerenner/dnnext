\documentclass[a4paper,11pt]{article}
\pdfoutput=1

\usepackage{jheppub} 
\usepackage[T1]{fontenc} % if needed
\usepackage{amsmath,amssymb}
%\usepackage[numbers,sort]{natbib}
%\hypersetup{colorlinks, citecolor=blue, linkcolor=blue, filecolor=blue, urlcolor=red}

\title{Background rejection in NEXT using deep neural networks}

\author{The NEXT Collaboration\newline}
\author[a,1]{J. Renner,\note{Corresponding author.}}
\author[b]{A. Farbin,}
\author[a]{J. Mu\~{n}oz Vidal,}
\author[a]{J. M. Benlloch-Rodr\'{i}guez,}
\author[a]{P. Ferrario,}
\author[a,2]{J. J. G\'omez-Cadenas,\note{Spokesperson.}}
\author[a]{V. \'{A}lvarez,}
\author[h]{C. D. R. Azevedo,}
\author[c]{F. I. G. Borges,}
\author[a]{S. C\'{a}rcel,}
\author[a]{J. V. Carri\'{o}n,}
\author[d]{S. Cebri\'{a}n,}
\author[a]{A. Cervera,}
\author[c]{C. A. N. Conde,}
\author[a]{J. D\'{i}az,}
\author[p]{M. Diesburg,}
\author[f]{R. Esteve,}
\author[c]{L. M. P. Fernandes,}
\author[h]{A. L. Ferreira,}
\author[c]{E. D. C. Freitas,}
%\author[e]{V. M. Gehman,}
\author[e]{A. Goldschmidt,}
\author[q]{D. Gonz\'{a}lez-D\'{i}az,}
\author[i]{R. M. Guti\'{e}rrez,}
\author[j]{J. Hauptman,}
\author[c]{C. A. O. Henriques,}
\author[k]{J. A. Hernando Morata,}
\author[f]{V. Herrero,}
\author[b]{B. Jones,}
\author[l]{L. Labarga,}
\author[a]{A. Laing,}
\author[p]{P. Lebrun,}
\author[a]{I. Liubarsky,}
\author[a]{N. L\'{o}pez-March,}
\author[a]{D. Lorca,}
\author[i]{M. Losada,}
%\author[f]{A. Mar\'{i},}
%\author[e]{T. Miller,}
\author[r]{J. Mart\'{i}n-Albo,}
\author[k]{G. Mart\'{i}nez-Lema,}
\author[a]{A. Mart\'{i}nez,}
\author[a]{F. Monrabal,}
%\author[a]{M. Monserrate,}
\author[c]{C. M. B. Monteiro,}
\author[f]{F. J. Mora,}
\author[h]{L. M. Moutinho,}
\author[a]{M. Nebot-Guinot,}
\author[a]{P. Novella,}
\author[b]{D. Nygren,}
\author[p]{A. Para,}
%\author[m]{J. L. P\'{e}rez-Aparicio,}
%\author[l]{J. P\'{e}rez,}
\author[a]{M. Querol,}
\author[n]{L. Ripoll,}
\author[a]{J. Rodr\'{i}guez,}
\author[c]{F. P. Santos,}
\author[c]{J. M. F. dos Santos,}
\author[a]{L. Serra,}
\author[e]{D. Shuman,}
\author[a]{A. Sim\'{o}n,}
\author[o]{C. Sofka,}
\author[a]{M. Sorel,}
%\author[o]{T. Stiegler,}
\author[f]{J. F. Toledo,}
\author[n]{J. Torrent,}
\author[g]{Z. Tsamalaidze,}
\author[h]{J. F. C. A. Veloso,}
%\author[d]{J. A. Villar,}
\author[o,3]{J. White,\note{Deceased.}}
\author[o]{R. Webb,}
\author[a]{N. Yahlali,}
\author[i]{H. Yepes-Ram\'{i}rez}

\affiliation[a]{Instituto de F\'{i}sica Corpuscular (IFIC), CSIC \& Universitat de Val\`{e}ncia,\\ 
	Calle Catedr\'{a}tico Jos\'{e} Beltr\'{a}n, 2, Paterna, Valencia, 46980 Spain}
\affiliation[b]{University of Texas at Arlington\\
	701 S. Nedderman Drive, Arlington, Texas, 76019 USA}
\affiliation[c]{Departamento de Fisica, Universidade de Coimbra, \\
	Rua Larga, Coimbra, 3004-516 Portugal}
\affiliation[d]{Lab. de F\'{i}sica Nuclear y Astropart\'{i}culas, Universidad de Zaragoza,\\
	Calle Pedro Cerbuna, 12, Zaragoza, 50009 Spain}
\affiliation[e]{Lawrence Berkeley National Laboratory (LBNL),\\
	1 Cyclotron Road, Berkeley, California, 94720 USA}
\affiliation[f]{Instituto de Instrumentaci\'{o}n para Imagen Molecular (I3M), Universitat Polit\`{e}cnica de Val\`{e}ncia,\\
	Camino de Vera, s/n, Edificio 8B, Valencia, 46022 Spain}
\affiliation[g]{Joint Institute for Nuclear Research (JINR),\\
	Joliot-Curie, 6, Dubna, 141980 Russia}
\affiliation[h]{Institute of Nanostructures, Nanomodelling and Nanofabrication (i3N), Universidade de Aveiro,\\
	Campus de Santiago, Aveiro, 3810-193 Portugal}
\affiliation[i]{Centro de Investigaciones, Universidad Antonio Nari\~{n}o,\\
	Carretera 3 este No. 47A-15, Bogot\'{a}, Colombia}
\affiliation[j]{Department of Physics and Astronomy, Iowa State University,\\
	12 Physics Hall, Ames, Iowa, 50011-3160 U.S.A.}
\affiliation[k]{Instituto Gallego de F\'{i}sica de Altas Energ\'{i}as (IGFAE), Univ. de Santiago de Compostela,\\
	Campus sur, R\'{u}a Xos\'{e} Mar\'{i}a Su\'{a}rez N\'{u}\~{n}ez, s/n, Santiago de Compostela, 15782 Spain}
\affiliation[l]{Departamento de F\'{i}sica Te\'{o}rica, Universidad Aut\'{o}noma de Madrid,\\
	Ciudad Universitaria de Cantoblanco, Madrid, 28049 Spain}
\affiliation[m]{Dpto. de Mec\'{a}nica de Medios Continuos y Teor\'{i}a de Estructuras, Univ. Polit\`{e}cnica de Val\`{e}ncia,\\
	Camino de Vera, s/n, Valencia, 46071 Spain}
\affiliation[n]{Escola Polit\`{e}cnica Superior, Universitat de Girona,\\
	Av. Montilivi, s/n, Girona, 17071 Spain}
\affiliation[o]{Department of Physics and Astronomy, Texas A\&M University,\\
	College Station, Texas, 77843-4242 U.S.A.}
\affiliation[p]{Fermi National Accelerator Laboratory,\\
	Batavia, Illinois, 60510 U.S.A.}
\affiliation[q]{CERN, European Organization for Nuclear Research,\\
	Geneva, 1211 Switzerland}
\affiliation[r]{Department of Physics, University of Oxford,\\
	Parks Road, Oxford, OX1 3PU United Kingdom}

% e-mail addresses: one for each author, in the same order as the authors
\emailAdd{jrenner@ific.uv.es}


\bibliographystyle{plain}
\input{commands}

\abstract{We investigate the potential of using deep learning techniques to reject background 
events in searches for neutrinoless double-beta decay with high pressure xenon time projection 
chambers capable of detailed track reconstruction.  The differences in the topological signatures of background and signal events can be learned by deep neural networks via training over many thousands of events.  These networks can then be used to classify
	further events as signal or background, providing an additional background rejection factor at an acceptable loss of
	efficiency.  This method is found to perform substantially better than previous methods developed based on the use of the
	same topological signatures and has the potential for further improvement.}

\keywords{Neutrinoless double beta decay; deep neural networks; TPC; high-pressure xenon chambers;  Xenon; NEXT-100 experiment}



\begin{document} 
\maketitle
\flushbottom

\section{Introduction}\label{sec:intro}
Double beta decay with neutrino emission (\bbtnu) is a  process in which two simultaneous $\beta$-decays occur within a nucleus,

\begin{equation}
 (Z,A) \rightarrow (Z+2,A) + 2e^{-} + 2\bar{\nu}_{e}.
\end{equation}

This process is allowed in the Standard Model and has been observed in several isotopes.  Double-beta decay has also been
postulated to exist in the zero-neutrino mode, or neutrinoless double-beta decay (\bbonu), in which the two 
antineutrinos are not emitted and the total energy released in the decay, \Qbb, is 
carried away by the two electrons.  The observation of \bbonu\ would imply that the neutrino is its own anti-particle, that is, a
a Majorana particle \cite{Schechter_1982}, amongst other important physical implications (see for example \cite{GomezCadenas:2013ue, Cadenas_2012, Avignone_2008}).

After 75 years of experimental effort, no compelling evidence for the existence of \bbonu\ decay has been obtained.  For a given isotope, the lifetime of \bbonu\,decay depends on a nuclear matrix element, 
which can be calculated to some uncertainty, and the square of the effective neutrino mass $|m_{\beta\beta}|^2 = |\sum_{i=e,\nu,\tau}U_{ei}^2m_{i}|^2$ which is a combination of the neutrino
masses $m_{i}$ and neutrino mixing matrix elements $U_{ei}$.  The lifetime is of the order of $10^{25}-10^{26}$~years for a degenerate neutrino mass hierarchy ($m_1 \sim m_2 \sim m_3$), $10^{26}-10^{27}$~years for an inverted 
neutrino mass hierarchy ($m_1 \ll m_2 < m_3$), and longer than $10^{27}$~years  for a normal mass hierarchy ($m_1 < m_2 \ll m_3$).  Experiments of the current generation deploy approximately
100 kg of the candidate isotope and are subject to several tens of counts per year of background events in their region of interest of energy selection near $Q_{\beta\beta}$\cite{GomezCadenas:2013ue}.  These experiments
will be capable of probing only the parameter space corresponding to the degenerate mass hierarchy, perhaps pushing into the inverted hierarchy.  In order to completely cover the parameter 
space of the inverted mass hierarchy, experiments employing candidate isotope masses at the ton-scale with background rates of (at most) few counts per ton-year will be required  \cite{Gomez-Cadenas:2015twa}.  

One of the technologies currently being developed is that of high pressure xenon (HPXe) Time Projection Chambers (TPCs). In particular, the NEXT collaboration \cite{Gomez-Cadenas:2014dxa} is building a HPXe TPC capable of holding 100 kg of xenon enriched at 90\% in the \bb\ decaying isotope \XE. NEXT operates at 15 bar and uses electroluminescent (EL) amplification of the ionization signal to optimize energy resolution. The detection of EL light provides an energy measurement using 60 photomultipliers (PMTs) located behind the cathode (the \emph{energy plane}) as well as tracking  via a dense array of about 8,000 silicon photomultipliers (SiPMs) located behind the anode (the \emph{tracking plane}).
In addition to performing a competitive search for \bbonu, NEXT will explore potential 
techniques for operation and background rejection at the ton-scale.  

The NEXT collaboration has already built and tested several kg-scale prototypes, NEXT-DBDM \cite{Alvarez:2012kua} and
NEXT-DEMO \cite{Alvarez:2012xda,Alvarez:2012kua,Alvarez:2013gxa,Lorca:2014sra}, which have both demonstrated the excellent energy resolution (extrapolated to 0.5-0.7\% FWHM at
$Q_{\beta\beta}$) obtainable in high pressure xenon gas.  NEXT-DEMO has demonstrated the feasibility of signal/background discrimination based on the topology of reconstructed tracks,
an essential component to identifying \bbonu\,events and rejecting background events (see section \ref{sec:topology}).  The collaboration is currently commissioning the first phase of the experiment, the so called NEXT-NEW (or NEW for short\footnote{The name honours the memory of the late professor James White, whose knowledge and generosity were essential to launch the experiment.}). NEW deploys a  mass of 10 kg of xenon at 15 bar, the energy plane hosts 12 PMTs and the tracking plane near 2,000 SiPMs. Operation is foreseen in 2016 and 2017, while NEXT-100 is scheduled to start operations in 2018.  By confirming the ability to obtain good energy resolution and reconstructed tracks at several different scales, NEXT 
intends to confirm the suitability of high pressure xenon gas for operation at the ton-scale.


The NEXT background model predicts a background rate of $5 \times 10^{-4}$~\ckky\ in the ROI  \cite{Martin-Albo:2015rhw}. The energy resolution for NEXT-100 is assumed to be 0.7\% FWHM at \Qbb\ ($\sim$ 17 keV).  The experiment expects, therefore less than one count of background per 100 kg and year of exposure, and thus its sensitivity to \Tonu\ is not dominated by background subtraction and increases rapidly with exposure. The expected sensitivity to the \bbonu\ half-life is $\Tonu > 7 \times 10^{25}$~yr for a exposure of 300 kg$\cdot$yr. This translates into a \mbb\ sensitivity range of $[90-180]$~meV, depending on the nuclear matrix element.

A central feature of a HPXe TPC is the capability of imaging electron tracks providing a {\bf topological signature} (TS)  that can be used to separate signal events (the two electrons emitted in a \bbonu\ decay) from background events (mainly due to single electrons with kinetic energy comparable to the end-point of the \bbonu\ decay, \Qbb). In this paper, we study the performance of the TS, analyzing how it is affected by the various physics processes involved in the propagation of electrons in dense gas, as well as by the detector spatial resolution. We use both the conventional reconstruction of electrons in NEXT describe in \cite{NEXT_topology}, and an alternative techniques based in the use of deep neural networks, comparing their relative performance. 

This paper is organized as follows.  Section \ref{sec.topology} describes the NEXT topological signature. The fast simulation used for this study is described in section \ref{sec.MC}. analysis of such tracks in the presence of an external magnetic field is described in section \ref{sec.magmotion}.  In section \ref{sec.curvature}, the analysis procedure is discussed, and the Monte Carlo data sample to which it is applied is described in section \ref{sec.track}.  Finally, the main results are shown in sections \ref{sec.results} and \ref{sec.improvedanalysis}, and their implications are discussed in section \ref{sec.outlook}.



%NEXT (Neutrino Experiment with a Xenon TPC) \cite{Gomez-Cadenas:2014dxa} is an experiment to search for neutrinoless double-beta decay using a Time Projection Chamber (TPC) filled with 
%high-pressure xenon gas (HPXe), enriched to 90\% in  $^{136}$Xe.  
%The detector uses electroluminescence to amplify the signal and optical sensors (photomultipliers and the so called silicon photomultipliers or SiPMs) to readout both the primary scintillation light (S1), defining the start-of-the-interaction and the secondary scintillation (S2) produced by the amplification, in the electroluminescence region of the drift electrons (see figure \ref{fig.SS}). The photomultipliers are located behind the cathode, forming the so-called energy plane, while the SiPMs, located behind the anode, define a matrix of pixels called the tracking plane. 
% in which 
%ionization electrons are drifted in a region of relatively low electric field to a narrow region of relatively high electric field, in which they are then accelerated to energies high enough to excite but not 
%ionize the atoms of the xenon gas.  These excitations give rise to the emission of electroluminescent light which is detected by an energy plane of 60 photomulitplier tubes (PMTs) and a tracking 
%plane of about 8000 silicon photomultipliers (SiPMs).  The detected electroluminescent light signal is called (S2), and can be compared in time with the light detected (S1) due to the excitations 
%produced during the initial creation of the ionization track to determine the z-coordinate of its production.  
%The pattern of light observed on the tracking plane is used to compute the x-y location of the ionization electrons producing the corresponding S2.  The result, combined with the time at which light is recorded, is a 3D image of the ionization track produced within the 
%detector.  The amount of S2 light detected by the energy plane gives an accurate measurement of the energy of the event.  Together this information can be used to identify potential 
%\bbonu\,events from the various energy depositions produced in the active volume.
%
%\begin{figure}[!htb]
%	\centering
%	\includegraphics[width= 0.95\textwidth]{fig/SoftAsymmetric_bound.pdf}
%	\caption{Production and detection of S1 and S2 in an asymmetric HPXe TPC (figure from \cite{MartinAlbo_thesis}).} \label{fig.SS}
%\end{figure}

%In addition to performing a competitive search for \bbonu, NEXT will explore potential 
%techniques for operation and background rejection at the ton-scale.  The NEXT collaboration has already built and tested several kg-scale prototypes, NEXT-DBDM \cite{Alvarez:2012kua} and
%NEXT-DEMO \cite{Alvarez:2012xda,Alvarez:2012kua,Alvarez:2013gxa,Lorca:2014sra}, which have both demonstrated the excellent energy resolution (extrapolated to 0.5-0.7\% FWHM at
%$Q_{\beta\beta}$) obtainable in high pressure xenon gas.  NEXT-DEMO has demonstrated the feasibility of signal/background discrimination based on the topology of reconstructed tracks,
%an essential component to identifying \bbonu\,events and rejecting background events (see section \ref{sec:topology}).  The collaboration is currently commissioning the first phase of the experiment, the so called NEXT-NEW (or NEW for short\footnote{The name honours the memory of the late professor James White, whose knowledge and generosity were essential to launch the experiment.}). NEW deploys a  mass of 10 kg of xenon at 15 bar, the energy plane hosts 12 PMTs and the tracking plane near 2,000 SiPMs. Operation is foreseen in 2016 and 2017, with a possible extension to 2018. It will be followed by NEXT-100, deploying 100 kg of xenon at 15 bar, 60 PMTs in the energy plane and near 8,000 SiPMs in the tracking plane. 
%containing about 20\% of the sensors of the 100 kg detector (NEXT-100).  By confirming the ability to obtain good energy resolution and reconstructed tracks at several different scales, NEXT 
%intends to confirm the suitability of high pressure xenon gas for operation at the ton-scale.

\section{Imaging tracks in a HPXe-EL TPC}
\label{sec.topology}

\begin{figure}[!htb]
\centering
\includegraphics[width= 0.95\textwidth]{fig/nextEL.png}
\caption{Principle of operation of an asymmetric HPXe TPC with EL readout.} \label{fig.SS}
\end{figure}

Figure \ref{fig.SS} shows the principle of operation of an asymmetric HPXe TPC using proportional electroluminescent (EL) amplification of the ionization signal (as is the case for NEXT-100). The detection process involves the use of the prompt scintillation light ($S_1$) from the gas as the start-of-event time, and the drift of the ionization charge to the anode by means of an electric field ($\sim0.3$ kV/cm at 15 bar) where secondary EL scintillation ($S_2$) is produced in a narrow region defined by two highly transparent meshes (called the EL gap or ELG).  High voltages are applied to the two meshes to establish an electric field of $\sim 20$ kV/cm at 15 bar in this region. The detection of EL light provides an energy measurement using PMTs in the case of NEXT-100 located behind the cathode (the \emph{energy plane}). The reconstruction of the track topology is carried out with a dense array of SiPMs located behind the anode (the \emph{tracking plane}). The $x$-$y$~coordinates are found using the information provided by the tracking plane, while $z$~is determined by the drift time between the detection of $S_1$~and $S_2$. For each reconstructed space point, the detector also measures the energy deposited. Thus, the track is imaged as a collection of hits. Each hit is defined by a 3D space coordinate and by an associated energy deposition, as (x,y,z,E).

%%%%%
\begin{figure}[!htb]
\centering
\includegraphics[width= 0.95\textwidth]{fig/TrackSignature.pdf}
\caption{Monte Carlo simulation of a signal (\bbonu) event (left) and a  background event (right) in xenon gas at 15~bar. The color corresponds to energy deposition in the gas. The signal consist of two electrons emitted from a common vertex, and thus it features large energy depositions  (blobs) at both ends of the track. Background events are, typically, single-electron tracks (produced by photoelectric or Compton interactions of high energy gammas emitted by \BI\ or \TL\ isotopes), and thus feature only one blob (figure from \cite{MartinAlbo_thesis}).} \label{fig.ETRK2}
\end{figure}
%%%%%

%%%%%
\begin{figure}[!htb]
\centering
\includegraphics[width=0.45\textwidth]{fig/EnergyBlobsSignal.pdf}
\includegraphics[width=0.45\textwidth]{fig/EnergyBlobsTl208.pdf}
\caption{Probability distribution of signal (left) and background (right) events in terms of the energies of the end-of-track blobs. The blob labelled as `1' corresponds to the more energetic one, whereas `blob 2' corresponds to the less energetic of the two. In a signal event, the blobs have, on average, the same energy. In a background event, blob 1 has an energy similar to that of a signal event while the energy of blob 2 is very small (figure from \cite{MartinAlbo_thesis}).} \label{fig.BLOBS}
\end{figure}
%%%%%

Electrons (and positrons) moving through xenon gas lose energy at an approximately fixed rate until they become non-relativistic. At the end of the trajectory the $1/v^2$~ rise of the energy loss (where $v$~ is the speed of the particle) leads to a significant energy deposition in a compact region, which will be referred to as a ``blob''. The two electrons produced in double beta decay events appear as a single continuous trajectory with a blob at each end (figure \ref{fig.ETRK2}-left). The main background in NEXT comes from high energy gammas emitted in \TL\ and \BI\ decays, which occur naturally in the detector materials as part of the \THT\ and \UTT\ chains, entering the active volume of the detector. These gammas convert in the gas through photoelectric, Compton and pair production processes. These electrons typically leave a single continuous track with only one blob (figure \ref{fig.ETRK2}-right). 
Reconstruction of the signal and background topology, using the tracking plane provides a powerful means of background rejection. For each track, the energy in both extremes of the track is measured and labelled as $E_{b1}$~ (the energy of the most energetic energy deposition), and $E_{b2}$~ (the least energetic energy deposition). In a signal event, $E_{b1} \sim E_{b2} $, while for background events $E_{b1} >> E_{b2} $. Figure \ref{fig.BLOBS} shows how this feature can be used to separate signal from background. 

\subsection{Reconstruction of tracks in a HPXe-EL TPC}Reconstruction of tracks in an electroluminescent HPXe is complicated by the diffusion of the charge cloud during drift and also by the nature of the read-out. Scintillation light is produced over the whole width of the EL gap (5 mm in NEXT-100) spreading the signal from a single electron over a time inversely proportional to the drift velocity within the gap ($\sim$ 2 $\mu$s). Additionally, the EL light is produced isotropically and, therefore, the signal produced by the passage of an electron through the gap is expected to arrive at the tracking plane ($\sim$ 7.5 mm behind the anode) over the area defined by the intersection of the plane with the sphere of light.
In a previous paper \cite{Lorca:2014sra}, the NEXT collaboration demonstrated that a ``point-like''deposition of charge due to the absorption of a point-like source (such as the xenon K$_\alpha$ X-rays) can be parameterised as a two dimensional Gaussian with a standard deviation of $\sim$ 8 mm where the spread due to EL light production is the dominant effect with subdominant contributions from transverse diffusion of the charge. Longitudinally, the expected spread has a noticeable dependence on the drift distance since the diffusion dominates. K$_\alpha$ events are expected to have widths in $z$~ with standard deviations of between 0.5 mm, for very short drifts, to about 5 mm for the longest drifts. In order to optimise the reconstruction of tracks these values must be taken into account by dividing the signal information into appropriate time slices and using charge information from clustered SiPM channels.
The standard NEXT algorithm  searches for clusters around local maxima and then proceeds iteratively, selecting first the channel with maximum charge and forming a cluster with the first ring of sensors around it. The cluster information is then used to build a hit, whose $x$~ and $y$~ position are reconstructed as the barycentre of the charge information. 

Once a set of hits is found, a connectivity criterium is  defined so that the hits belonging to each separate particle can be grouped into tracks. The procedure is as follows: first, the active volume is divided into 3D pixels, known as ``voxels'', of fixed dimensions. Each voxel is given an energy equal to the sum of the energies of all the hits which fall within its boundaries. The collection of voxels obtained in such a way can be regarded as a graph, defined as a set of nodes and links that connect pairs of nodes. Two voxels can then be considered connected if they share a face, an edge or a corner, with each pair of connected voxels being given a weight equal to the geometric distance between their centres. Next, the ``Breadth First Search'' (BFS) algorithm  is used to group the voxels into tracks and to find their end-points and length. The BFS algorithm is a graph search algorithm which finds the minimum path between two connected nodes, starting from one node and exploring all its neighbours first, then the second level neighbours and so on, until it reaches the second node. The BFS algorithm divides the voxels into connected sets, known as tracks and finds their end-points, defined as the pair of voxels with largest distance between them, where the distance of two voxels is the shortest path that connects them. The distance between the end-points is the length of the track. See \cite{NEXT_topology} for a thorough discussion.
The choice of the voxel size is a compromise between a fine granularity and conservation of connectivity, which depends on the hit-finder algorithm in use. In \cite{NEXT_topology},  the best connectivity  was  found for voxels of 
$10 \times 10 \times 10 \mathrm{~cm^3}$. The analysis described in \cite{Martin-Albo:2015rhw} used voxels
of similar size ($10 \times 10 \times 5 \mathrm{~cm^3}$).  Improvements in the hit-finder algorithm (or the use of alternative methods such as DNNs) may allow, in principle for smaller voxels. However, the size of the voxel also reflects the effect of the spatial resolution, which in turn depends of: 
\begin{enumerate}
\item {\em Tracking plane design:} this includes the pitch of the SiPMs in the tracking plane as well as the SiPM response. Indeed, the use of SiPMs with very low dark current and high gain allows one to determine the location of an event by weighting the position of each sensor with the light recorded, thus improving dramatically the ``digital'' resolution, which goes as $\sim$pitch/$\sqrt{12}$. The digital point resolution corresponding to a pitch of 10 mm (NEXT-100) is 10$/\sqrt{12} \sim 3$~mm. Using weighted information (e.g, local barycenter algorithms), the point resolution improves to about 1 mm (see \cite{Lorca:2014sra}). 
\item {\em The width of the EL region:}
The non-zero width of the EL gap adds an extra resolution term in the $z$~coordinate which goes like $w/\sqrt{12}$~where $w$~is the width of the grid. For the NEXT-100, $w\sim 5$~resulting also in a resolution of about 1.5 mm. At the same time, the non-negligible distance (about 8 mm) between the gate grid (the plane that defines the beginning of the EL region) and the sensors in the tracking plane, spreads the signal of a single electron over several SiPMs. The light distribution is gaussian and a fit to the profile recovers the position of the ionization electron.
\item {\em Diffusion of the drifting electron cloud:}  both transverse and  longitudinal and  diffusion are high in pure xenon (of the order of $10 (5) $~mm/$\sqrt{\rm{m}}$). On the other hand, work in progress within the NEXT collaboration\cite{Azevedo:2015eok} suggests that adding small amounts of cooling gases such as \CHF\ or \CFF\ to pure xenon (at the level of 0.1 \% of \CHF\ or 0.01\% of \CFF\ reduce both transverse and longitudinal diffusion to some $2.0$~mm/$\sqrt{\rm{m}}$. This is one of the most important upgrades under study for the second phase of NEXT-100. 
\end{enumerate}

%The standard NEXT reconstruction algorithm, the collection of energy depositions (``hits'') that are provided by the tracking plane are organized into an ordered track, so that the  beginning and the end of the track can be identified and the energy of the blobs lying in the track extremes computed.  This is a difficult task due to the wide variety of track geometries that can result from multiple scattering. Alternatively, the use of deep neural networks (DNNs) offers the possibility to treat the collection of hits produced by the tracking plane as an image, delegating to the DNN the task of learning how to classify images corresponding to signal and background classes. 
%
%The performance of the TS is affected by the physics of electron propagation in dense gas, which causes phenomena such as multiple scattering, emission of delta rays and Bremsstrahlung that results in some level of confusion between signal and background. It also depends on detector parameters, most importantly spatial resolution. Last but not least, it may be improved by the use of optimal algorithms. 

%
%
%\section{The NEXT Topological Signature}\label{sec:topology}
%One of the most important aspects of NEXT is its ability to image the ionization tracks produced by energetic electrons in its active volume.  Double-beta decay events have a distinct
%topological signature, e.g, the presence on the event of two electrons emitted from a common vertex. In a HPXe chamber, the vertex cannot be identified, nor the individual electrons separated, due to the confusing effect of multiple scattering. However, the signature of those ``double-electron'' (or 2e) tracks is substantially different from that of a single electron (1e) produced, for example, by photoelectric or Compton 
%conversion of a high-energy gamma ray.  Figure \ref{fig.ETRK2} compares the two types of
%tracks. A single electron (figure  \ref{fig.ETRK2}--right) appears in the chamber as a long and relatively smooth track near its beginning and becomes increasingly contorted, due to increasing multiple scattering (as it loses energy ionizing the gas) until the electron comes to a stop, depositing
%its final several hundred keV of energy in a relatively smaller volume, which we describe as a ``blob.'' 
%%is due to several factors.  First, the ionization density ($dE/dx$) increases rapidly with decreasing energy as the energy of the electron drops below about 1 MeV.  Furthermore, electron multiple scattering, the repeated scattering of the electron throughout the creation of its ionization path, also becomes more intense at lower energies.  Together
%%these effects lead to a single-electron track that is long and relatively smoother near its beginning and becomes increasingly contorted until the electron comes to a stop, depositing
%%its final several hundred keV of energy in a relatively smaller volume, which we describe as a ``blob.''  
%A double-beta event (figure  \ref{fig.ETRK2}--left)  looks like two such tracks beginning at a single vertex.  
%%Figure \ref{fig.ETRK2} compares the two types of
%%tracks.  
%In NEXT is possible to separate signal from backgrounds using this topological signature. The conventional algorithm developed by the collaboration is based in reconstructing an ordered
%track, locating the endpoints, and determining whether the energy in those endpoints (blobs) is sufficiently large. Alternatively it is possible to use deep learning techniques, as discussed in this paper.   
%
%\begin{figure}[!htb]
%	\centering
%	\includegraphics[width= 0.95\textwidth]{fig/TrackSignature.pdf}
%	\caption{Monte Carlo simulated \bbonu\,(left) and background (right) events.  The simulation was done in xenon gas at a pressure of 15~bar. Signal events consist of two electrons emanating
%		from a common vertex, producing two initially smooth tracks ending in two dense energy depositions (or ``blobs'').  Background events consist of one long track terminating in one
%		single ``blob'' (figure from \cite{MartinAlbo_thesis}).} \label{fig.ETRK2}
%\end{figure}

\section{Monte Carlo Simulation}
\label{sec.MC}

NEXUS \cite{MartinAlbo_thesis}, the  GEANT4-based \cite{GEANT4} 
Monte Carlo simulation of the NEXT-100 detector permits an accurate modelling of the detector geometry and provides the tools to carry on both full and fast simulations of the apparatus response. 
A fast simulation has been chosen for this study, 
given the need to generate a very large number of events for the detailed physics studies presented here, as well as for the training of the DNNs.

The simulation starts generating a large number of signal and background events. \bbonu\ events are randomly created throughout the active region of the detector, while the leading background events---gamma rays of energies 2.447 MeV and 2.614 MeV corresponding to gammas emitted by daughters of $^{214}$Bi and $^{208}$Tl,
respectively, see \cite{Martin-Albo:2015rhw} for a thorough discussion---are shot from several different regions (e.g, energy and tracking plane, detector vessel, etc.) within the detector geometry. 
The resulting locations and magnitudes of the energy depositions in the active volume are recorded as ``true hits''. To speed the propagation of the tracks, a minimum step size of 1 mm is setup in NEXUS.

The fast-simulation approach to produce reconstructed objects starting from the true hits, takes into account the energy and spatial resolution. The former is introduced by simply smearing the total energy deposited by the event by the expected NEXT-100 resolution (we assume, conservatively, 0.7\% FWHM at \Qbb); the later, by combining the resolution associated to the
pixel pitch, the EL width and the diffusion into the voxel size. Thus, to emulate the response of NEXT-100 operating with pure xenon, the true hits are replaced by voxels of $10 \times 10 \times 5 \mathrm{~mm^3}$. Instead, the response of NEXT-100 under conditions of low diffusion is emulated by replacing the true hits by voxels of $2 \times 2 \times 2 \mathrm{~mm^3}$. Comparison between data and Monte Carlo in  \cite{NEXT_topology}, showed that choosing a voxel size of the same order than the maximum spread due to diffusion results in an acceptable (although somewhat conservative) simulation of the detector response. We have therefore considered a third case, with voxels of $5 \times 5 \times 3 \mathrm{~mm^3}$, which may be regarded as an optimistic emulation of the response of NEXT-100 with pure xenon, or a conservative simulation of the response with low-diffusion mixtures. 

Notice that the procedure os smearing the true hits by some gaussian error, usual in the fast-simulation of many experiments, doest not work well here, since the concept of ``point resolution'' is not well defined in an HPXe-EL, due to the effects already discussed (light spread in the EL gap and diffusion) combined with the twisted shape of the track. The fact that, for any given time slice, the tracking plane is receiving light from the portion of the track inside the EL grid, which in turn contains ionization electrons from several points of the track (due to diffusion), can be better captured replacing each true hit by a voxel chosen to integrate the typical size of the above effects, that by a ``smeared hit''. This is also the case when working with reconstructed data in an HXPe-EL. As discussed above, the hits produced by the tracking plane must be replaced by voxels in order to produce a connected track. 

\section{The topological signature}
\label{sec.top}

\subsection{Pre-selection of data}
\label{ssec.prep}

 Once the list of voxels is obtained, the data is processed as follows: 
\begin{enumerate}
	\item[1.] A fiducial is applied, ensuring that no more than 10 keV of energy was deposited within 2 cm of the edges of the active region.
	\item[2.] Only events near \Qbb\ (in the energy window between 2.4 and 2.5 MeV) are accepted.
	\item[3.] Tracks are formed using the BFS algorithm and only events with exactly one track are accepted.  This cut effectively suppresses background events accompanied by the emission of x-rays associated to the de-excitation of the xenon atom (e.g, after a photoelectric interaction). 
\end{enumerate}

%%%%
Table \ref{tbl.FastAnalysisResults} shows how the set of cuts described above reduces the signal and the primary backgrounds for Monte Carlo generated events with voxel sizes of $2 \times 2 \times 2 \mathrm{~mm^3}$ and $10 \times 10 \times 5 \mathrm{~mm^3}$ (as background events were generated from several regions of the detector, a subset of events generated from a single region is shown).  Notice that, in order to characterize the rejection power of the topological signature, a relatively large energy window of 100 keV around \Qbb\ is used. The total rejection power of NEXT will be the combination of the rejection power achieved by the pre-selection (cuts 1-3 above), the topological signature cut (e.g, the requirement that the track is a 2e), discussed in more detail below, and a final, stricter energy cut that accepts events in a relatively narrow region of interest ROI around \Qbb. See \cite{Martin-Albo:2015rhw} for a detailed discussion.

\begin{table}[!htb]
	\begin{center}
		\caption[Fast analysis summary]{\label{tbl.FastAnalysisResults}Fraction of events remaining after each analysis cut, for signal events ($10^6$ initial events generated) and background events from $^{208}$Tl and $^{214}$Bi ($10^9$ initial events generated).}
		\begin{tabular}{c|cc|cc|cc}
			\\
			 & \multicolumn{2}{c}{\textbf{Signal Events}} & \multicolumn{2}{c}{\textbf{BG Events ($^{208}$Tl)}} & \multicolumn{2}{c}{\textbf{BG Events ($^{214}$Bi)}}\\
			\textbf{Cut} & 2x2x2 & 10x10x5 & 2x2x2 & 10x10x5 & 2x2x2 & 10x10x5\\
			\hline
			(Initial events) & 1.0 & 1.0 & 1.0 & 1.0 & 1.0 & 1.0\\
			Fiducial & $6.76$\small{$\times 10^{-1}$} & $6.76$\small{$\times 10^{-1}$} & $1.78$\small{$\times 10^{-3}$} & $1.78$\small{$\times 10^{-3}$} & $2.17$\small{$\times 10^{-5}$} & $2.17$\small{$\times 10^{-5}$}\\
			%True E & $6.76$\small{$\times 10^{-1}$} & $6.76$\small{$\times 10^{-1}$} & $1.76$\small{$\times 10^{-3}$} & $1.76$\small{$\times 10^{-3}$} & $2.15$\small{$\times 10^{-5}$} & $2.15$\small{$\times 10^{-5}$}\\
			Smeared E & $6.64$\small{$\times 10^{-1}$} & $6.64$\small{$\times 10^{-1}$} & $2.14$\small{$\times 10^{-4}$} & $2.14$\small{$\times 10^{-4}$} & $1.59$\small{$\times 10^{-5}$} & $1.59$\small{$\times 10^{-5}$}\\
			1-Track & $3.71$\small{$\times 10^{-1}$} & $4.76$\small{$\times 10^{-1}$} & $4.02$\small{$\times 10^{-6}$} & $9.12$\small{$\times 10^{-6}$} & $8.08$\small{$\times 10^{-7}$} & $1.85$\small{$\times 10^{-6}$}\\
			Topology* & $3.13$\small{$\times 10^{-1}$} & $3.54$\small{$\times 10^{-1}$} & $3.20$\small{$\times 10^{-7}$} & $9.94$\small{$\times 10^{-7}$} & $6.60$\small{$\times 10^{-8}$} & $1.59$\small{$\times 10^{-7}$}\\
		\end{tabular}
	\end{center}
	* See section \ref{ssec:TopologicalAnalysis}
\end{table}

\subsection{The standard NEXT topological analysis}
\label{ssec:TopologicalAnalysis}
After pre-selection the events were classified as signal or background based on the presence of one or two ``blobs'' of energy in the
reconstructed track, using the BFS algorithm and choosing the longest of these paths to be the ordered path.  Note that such a path may not have included, 
in fact most likely did not include, all voxels in the event.  The first and last voxels in the path
were considered to be the beginning and end of the track.  The energy in all voxels that were located within a given radius $r_b$ of the beginning of the track was summed to give
an energy $E_{b,1}$, and similarly at the end of the track to give an energy $E_{b,2}$.  

The results depend on the size of the voxel, which in turn is chosen to reflect the expected performance of the detector under specific operating conditions, as discussed above. Operation with pure xenon corresponds to $10 \times 10 \times 5 \mathrm{~mm^3}$~voxels (conservative), operation with low diffusion mixtures correspond to voxel sizes of $2 \times 2 \times 2 \mathrm{~mm^3}$~(best expected case) and voxels of $5 \times 5 \times 3 \mathrm{~mm^3}$~represent an intermediate case (best case in pure xenon or conservative in low diffusion mixtures).  Examples of events voxelized with sizes of $10 \times 10 \times 5 \mathrm{~mm^3}$~ and
$2 \times 2 \times 2 \mathrm{~mm^3}$~ are shown in Figs. \ref{fig.exampleProjs10105} and \ref{fig.exampleProjs222}.

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.36]{fig/plt_h2D_vox_dnn3d_NEXT100_Paolina10105_v10x10x5_r200x200x200_2_bg.png}
	\includegraphics[scale=0.36]{fig/plt_h2D_vox_dnn3d_NEXT100_Paolina10105_v10x10x5_r200x200x200_3_si.png}
	\caption{\label{fig.exampleProjs10105}Projections in xy, yz, and xz for an example background (above) and signal (below) event voxelized with 10 x 10 x 5 mm$^3$ voxels.}
\end{figure}

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.36]{fig/plt_h2D_vox_dnn3d_NEXT100_Paolina222_v2x2x2_r200x200x200_0_bg.png}
	\includegraphics[scale=0.36]{fig/plt_h2D_vox_dnn3d_NEXT100_Paolina222_v2x2x2_r200x200x200_2_si.png}
	\caption{\label{fig.exampleProjs222}Projections in xy, yz, and xz for an example background (above) and signal (below) event voxelized with 2 x 2 x 2 mm$^3$ voxels.}
\end{figure}

The histogram of $E_{b,1}$ vs. $E_{b,2}$ is shown in figure \ref{fig.blobcuts} for both signal and
background events analyzed with both chosen voxel sizes.  In this case, the distance between a voxel and the extremes of the track was calculated as 
``along-the-track distance,'' in which the distance between any two voxels was integrated along the reconstructed track (as opposed to computing the Euclidean distance). 

\begin{figure}[!htb]
	\centering
	\includegraphics[scale = 0.49]{fig/blobcuts_bb0nu_10x10x5_E1vsE2.png}
	\includegraphics[scale = 0.49]{fig/blobcuts_Tl208_10x10x5_E1vsE2.png}	
	\includegraphics[scale = 0.45]{fig/blobcuts_bb0nu_2x2x2_E1vsE2.png}
	\includegraphics[scale = 0.45]{fig/blobcuts_Tl208_2x2x2_E1vsE2.png}
	\caption{Computed blob energies $E_{b,1}$ vs. $E_{b,2}$ for signal (left) and $^{208}$Tl background (right) events with 10 x 10 x 5 mm$^3$ voxelization (above) and 2 x 2 x 2 mm$^3$ voxelization (below).  The blob radius chosen was $r_b = 18$ mm for the 10 x 10 x 5 mm$^3$~ voxelization and $r_b = 15$ mm for the 2 x 2 x 2 mm$^3$~ voxelization.} \label{fig.blobcuts}
\end{figure}

Finally we apply a cut designed to choose signal events with two blobs and eliminate background events with only one blob, mandating that $E_{b,1}$ and $E_{b,2}$ are both greater than a threshold energy $E_{\mathrm{th}}$.  For the 10 x 10 x 5 mm$^3$ voxel size with $E_{\mathrm{th}} =$ 0.35 MeV, we eliminate all but 11.37\% of $^{208}$Tl background events and all but 10.07\% of $^{214}$Bi background events, and keep 74.22\% of signal events.  For the 2 x 2 x 2 mm$^3$ voxel size with $E_{\mathrm{th}} =$ 0.3 MeV we eliminate all but 8.79\% of $^{208}$Tl background events and all but 7.80\% of $^{214}$Bi background events, and keep 84.15\% of signal events. %% TABLE HERE, signal background!
% Later we will attempt to use DNNs in place of the cut on $E_{b,1}$ and $E_{b,2}$ to improve these results.

\section{Deep Learning}
The use of artificial neural networks to solve problems has been explored since the 1940s.  In recent years, with the dramatic increase in available computing power, the use of computationally
intense neural networks with many inner layers has become feasible.  These neural nets that are many layers deep, called deep neural networks (DNNs), are capable of learning large
amounts of data exhitibing a vast array of features.  This idea of ``deep learning'' has been applied to yield outstanding performance in solving difficult problems such as image and 
speech recognition.

Neural networks consist of layers of neurons which compute an output value based on one or several input values.  The output $z$ is a function of the weighted sum of the inputs $x_{i}$ plus a bias variable $b$, i.e. $z = f(\sum_{i}w_{i}x_{i} + b)$, where $f$ is called the activation function and $w_{i}$ are the weights of the neuron, one for each input.  The idea is that
with several layers of many neurons connected together, the values of the final (``output'') layer of neurons will correspond to the solution of some problem given the values input to the
initial layer (called the ``input'' layer).  The weights and biases of all neurons in the network together determine the final output value, and so the network must be trained (the weights and
biases must be adjusted) so that the network solves the correct problem.  This is done by using a training dataset, and for each training event, presenting input data to the network, 
examining its resulting output, and adjusting the weights and biases of the network in a manner that minimizes the discrepancy between the output of the final layer $a$ and the expected 
output $y$.  This adjustment procedure is done by computing a cost function which depends on the actual and expected outputs and quantifies the discrepancy between them, computing 
the gradients of the cost function with respect to the weights and biases in all neurons, and changing the weights and biases in a manner that minimizes the cost function.  After many training
iterations, the weights and biases in the network will ideally have converged to values that not only yield the expected output when the network is presented with an event from the training
dataset, but also yields the expected output when presented with similar events not used in training.  The technical
details behind implementing such a scheme mathematically will not be given here but are discussed at length in \cite{Nielsen_2016}.

Recently, multi-layer convolutional neural networks (CNNs) have been identified as a powerful technique for image recognition problems.  These neural networks consist of $m\times n$
convolutional layers - layers of neurons that share a common set of $m\times n$ weights and a bias.  The set of 
weights $+$ biases is called a filter or kernel, and this filter is combined in a multiplicative sum (a convolution) with an $m\times n$ subset of input neurons to give an output value.  The filter
is moved along the image, each time covering a different $m\times n$ subset of input neurons, and the set of output values corresponding to a single filter is called a feature map.  With this
strategy, the net can be trained to identify specific features of an image, and further convolutional layers can be used to analyze the higher-level features encoded in the feature maps output
from previous layers.  Often to reduce the amount of computation and neurons present in deeper layers, max-pooling operations are performed, in which the neuron with maximum output
value in an $m\times n$ window (or ``pool'') is selected, and all others in the pool are discarded.  Such an operation performed on a layer of neurons leads to a new layer of reduced size.
A deep CNN may be constructed from a series of several such convolutional operations and max-pooling operations, along with more conventional fully-connected layers, in which all neurons 
output from the previous layer are connected to the input of each neuron in the fully-connected layer, and other operations not discussed here (see figure \ref{fig.generalnn} for a general 
schematic).

\begin{figure}[!htb]
	\centering
	\includegraphics[scale = 0.6]{fig/general_nn.pdf}
	\caption{Schematic of a deep convolutional neural network for 2-category classification.  The input layer consists of the pixel intensities of an image, possibly in multiple color channels.  The 
		hidden layers consist of several different operations performed on the input neurons - this example shows a 3x3 convolution followed by a 3x3 max-pooling operation, with the resulting 
		neurons input to a fully-connected layer which feeds the two neurons in the output layer.  Rather than reading the values of the activation functions of
		the two neurons in the output layer, the values are converted to two values in a normalized exponential distribution.  These values can then be interpreted as probabilities of classification as
		signal or background.} \label{fig.generalnn}
\end{figure}

In this initial study, we make use of the GoogLeNet \cite{Googlenet}, which is a sophisticated 22-layers-deep convolutional network designed for image recognition.  As GoogLeNet was
designed to classify and identify a wide range of features in a full-color images, a more suitable network is likely to exist for our specific problem of classifying particle tracks based on
topology.  While further exploration of DNN architecture is essential to understanding the problem fully, our main goal in this study will be to show that DNNs can ``learn'' to classify 
NEXT events as signal or background better than previously developed conventional analysis methods.

\section{Event classification with a DNN}

Here we investigate the performance of a DNN in classifying events into two categories, ``signal'' and ``background,'' and compare the results to the conventional analysis described in
section \ref{ssec:TopologicalAnalysis}.  We chose to use the GoogLeNet DNN for this initial study, as its implementation was readily available in the Caffe \cite{jia2014caffe}
deep learning framework along with an interface, DIGITS \cite{DIGITS}, which allows for fast creation of image datasets and facilitates their input to several DNN models.  For each simulated
dataset, GoogLeNet was trained on several tens of thousands of input events on a single GPU (either a GeForce GTX TITAN or GeForce GTX TITAN X, depending on the dataset), and several
thousand additional events as validation.  Each event was input to the net as a .png image consisting of three
color (RGB) channels, one for each of three projections of the 3D voxelized track, (R, G, B) $\rightarrow$ (xy, yz, xz).  This information for a signal event and a background event was
shown earlier for different voxelizations in Fig. \ref{fig.exampleProjs222} and Fig. \ref{fig.exampleProjs10105}.

\subsection{Analysis of NEXT-100 Monte Carlo}\label{ssec:NEXTMCanalysis}
To compare the ability of the DNN to classify events directly with the performance of the topological analysis of section \ref{ssec:TopologicalAnalysis}, we consider NEXT-100 Monte Carlo 
events that have passed the pre-selection cuts described in \ref{ssec.prep}, with chosen voxel sizes of both 2 x 2 x 2 mm$^3$ and 10 x 10 x 5 mm$^3$.  For each chosen voxel size, the 
GoogLeNet DNN was trained on 30000 such events (15000 signal and 15000 background) over 30 epochs, 
and an independent set of events was used as a test dataset (6000 in the 2x2x2 voxel case and 4000 in the 10x10x5 case, split evenly between signal and background).  Because these were 
the exact same events as those used in the previous
topological analysis, the classification into signal and background from both analyses can be compared directly.  The results are shown in table \ref{tbl.DNNcomparison}.  The DNN
analysis performs better than the conventional analysis, but there is still potential room for improvement.  

\begin{table}[!htb]
	\begin{center}
		\caption[DNN analysis summary]{\label{tbl.DNNcomparison}Comparison of conventional and DNN-based analyses.  The comparison shows, for a given percentage of signal events
			correctly classified, the number of background events accepted (mistakenly classified as signal).}
		\begin{tabular}{rcc}
			\\
			\textbf{Analysis} & \textbf{Signal eff. (\%)} & \textbf{B.G. accepted (\%)}\\
			\hline
			DNN analysis (2 x 2 x 2 voxels) & 84.16 & 5.00\\
			Conventional analysis (2 x 2 x 2 voxels) & 84.15 & 8.79\\
			\hline
			DNN analysis (10 x 10 x 5 voxels) & 74.23 & 8.30\\
			Conventional analysis (10 x 10 x 5 voxels) & 74.22 & 11.37\\
		\end{tabular}
	\end{center}
\end{table}

Because the output layer of the DNN gives a probability that a given event is signal and a probability that it is background, and these probabilities add to 1, a threshold may be 
chosen for determining whether an event is classified as signal or background.  It can be simply chosen as 50\%, meaning the category with greatest probability is the classification of the
event, or it can be varied to reject further background at the expense of signal efficiency.  Figure \ref{fig_svsb} shows the corresponding pairs of signal efficiency and background 
rejection produced by variation of this threshold, while for the values reported in table \ref{tbl.DNNcomparison} the threshold was chosen such that the signal efficiency matched that reported in 
the conventional analysis.

\begin{figure}[!htb]
	\centering
	\includegraphics[scale=0.6]{fig/sigvsbg_DNN.pdf}
	\caption{\label{fig_svsb}Signal efficiency vs. background rejection for DNN analysis of voxelized (2x2x2 and 10x10x5 cubic mm), single-track NEXT-100 Monte Carlo events.}
\end{figure}

\subsection{Evaluating the DNN analysis}\label{ssec:DNNeval}
We now ask what is causing some significant fraction of the events to be misclassified in the analysis described in section \ref{ssec:NEXTMCanalysis}.  A similar analysis was run on 
several different Monte Carlo datasets generated with differing physics effects with the hopes of better understanding where potential improvements could be made.

A simple Monte Carlo, which we call the ``toy Monte Carlo'' or ``toy MC,'' was designed to produce ionization tracks of single-electron and two-electron events with a fixed energy
considering minimal physical effects.  Discrete energy depositions were produced with a step size less than 1 mm according to the average stopping power $dE/dx$ as tabulated by
NIST \cite{NIST_mac} for xenon at 15 atm.  Electron multiple scattering was modeled by casting random gaussian numbers to determine the angles $\theta_{x}$ and $\theta_{y}$ of deflection, 
assuming the particle's direction of travel is $\hat{\mathbf{z}}$, and the angles $\theta_{x}$ and $\theta_{y}$ are the angles between the scattered direction and $\hat{\mathbf{z}}$ projected on 
the x-z and y-z planes respectively, as

\begin{equation}\label{eqn_mscat}
\sigma^{2}(\theta_{x,y}) = \frac{13.6\,\,\mathrm{MeV}}{\beta p}\sqrt{dz/L_{0}}\bigl[1 + 0.038\ln(dz/L_{0})\bigr].
\end{equation}

\noindent where $dz$ is the thickness of xenon travelled in this step, $L_{0}$ is the radiation length in xenon, $p$ is the electron momentum in MeV/c, and $\beta = v/c$, assuming $c = 1$.

Such tracks were generated and voxelized similar to the procedure described in point 5 of section \ref{ssec:NEXT100MC}.  Note that no ``single-track'' cut was necessary because no
physics generating a secondary track was implemented.  Also no energy smearing was performed.  For background events, the track generation began with a single electron emitted in a
random direction with energy 2.4578 MeV, while for signal events, this energy was shared equally between two electrons emitted in random directions from a single initial vertex.  The DNN
classified the resulting events with nearly 100\% accuracy.  Several modifications were then made to attempt to gain insight into the physics causing the lower classification observed in the
more detailed Monte Carlo tracks.  First, a realistic distribution of energies of the two electrons in signal events \cite{Ponkratenko_2000} was used, and later the magnitude of the multiple scattering was doubled (the prefactor 13.6 in equation \ref{eqn_mscat} was increased to 27.2).  The electron energy distribution caused a loss of about 1\% in average accuracy, and the
increased multiple scattering an additional 1\%.  However, even the two effects together were not enough to account for the inaccuracy of about 7\% observed in the events produced by the
full Monte Carlo.

Therefore an alternate GEANT-based Monte Carlo was run in which the detector geometry was not present, and background events (single electrons) and signal events (two electrons emitted
from a common vertex with a realistic \bbonu\,energy distribution) were generated in a large box of pure xenon gas at 15 bar.  An insignificant amount of energy smearing was applied to these
events, and they were then subject to the same voxelization procedure and single-track cut as described in section \ref{ssec:NEXTMCanalysis} point 5.  Under these controlled conditions, many 
events could be generated with different aspects of the physics switched on/off.  It was confirmed that with the same physics as that used in the NEXT-100 Monte Carlo, the DNN classified events 
with similar accuracy as before.  Disabling bremsstrahlung seemed to have little effect on the accuracy.  Disabling energy fluctuations in GEANT had some small effect (approx. 1\% increase in
accuracy), and disabling the production of secondaries (disallowing the production of secondaries with a range of less than 20 cm) had a more sigificant effect (approx. 2.5\% increase in accuracy),
though still did not yield accuracy similar to the toy MC datasets.  It was found that disabling both energy fluctuations and the production of secondaries gave accuracies similar to the toy MC
(about 98\%), and therefore we can conclude these are the physical effects that are often deceiving the DNN.

A summary of the Monte Carlo simulations run and the classification accuracies obtained is given in table \ref{tbl.DNNsummary}.  

\begin{table}[!htb]
	\begin{center}
		\caption[DNN analysis summary]{\label{tbl.DNNsummary}Summary of DNN analysis for different Monte Carlo datasets.  The accuracy was computed assuming that the classification
			of the DNN corresponded to the category (signal or background) with the higher ($> 50$\%) probability.  In each case, approximately 15000 signal and 15000 background events were
			used in the training procedure, and between 2000-3000 signal and 2000-3000 background events independent of the training set were used to determine the accuracy.}
		\begin{tabular}{rrc}
			\\
			\textbf{2x2x2 voxels} & \textbf{Run description} & \textbf{Avg. accuracy} (\%)\\
			\hline
			\multicolumn{2}{r}{toy MC, ideal} & 99.8\\
			\multicolumn{2}{r}{toy MC, realistic \bbonu\,distribution} & 98.9\\
			\multicolumn{2}{r}{Xe box GEANT4, no secondaries, no E-fluctuations} & 98.3\\
			\multicolumn{2}{r}{Xe box GEANT4, no secondaries, no E-fluctuations, no brem.} & 98.3\\
			\multicolumn{2}{r}{toy MC, realistic \bbonu\,distribution, double multiple scattering} & 97.8\\
			\multicolumn{2}{r}{Xe box GEANT4, no secondaries} & 94.6\\
			\multicolumn{2}{r}{NEXT-100 GEANT4} & 93.1\\
			\multicolumn{2}{r}{Xe box GEANT4, no E-fluctuations} & 93.0\\
			\multicolumn{2}{r}{Xe box, no brem.} & 92.4\\
			\multicolumn{2}{r}{Xe box, all physics} & 92.1\\
			\textbf{10x10x5 voxels} & & \\
			\hline
			\multicolumn{2}{r}{NEXT-100 GEANT4} & 86.5
		\end{tabular}
	\end{center}
\end{table}

%(Do we want to discuss further the ``zoology'' of events misclassified by the DNN?  The production of a large secondary (``delta'') electron near the beginning of the track in a single-electron event, for example, could produce an event that looks almost indistinguishable from a double-beta event in topology.)

\section{Conclusions}
A DNN-based analysis using GoogLeNet with just three projections seems to be capable of outperforming, in signal/background separation, a conventional analysis based on locating energy ``blobs'' at the ends of the tracks produced by energetic electrons.  The production of secondaries coupled with energy fluctuations in energy deposition seems to be the principle cause of accuracy loss in the DNN analysis, at least in the case of high-resolution ($\sim$ 2 mm) reconstruction.  Future studies geared toward developing a DNN targeted on the problem at hand, and attempting to extract information on what characteristics of the tracks it is ``learning,'' would lead to a more complete understanding of the possibilities and limitations of a DNN analysis.

\acknowledgments

This work was supported by the European Research Council under the Advanced Grant 339787-NEXT and the Ministerio de Econom\'{i}a y Competitividad of Spain under Grants CONSOLIDER-Ingenio 2010 CSD2008-0037 (CUP), FPA2009-13697-C04-04, FPA2009-13697-C04-01, FIS2012-37947-C04-01, FIS2012-37947-C04-02, FIS2012-37947-C04-03, and FIS2012-37947-C04-04.  JR acknowledges support from a Fulbright Junior Research Award.

\bibliography{dnnext}

\end{document}
